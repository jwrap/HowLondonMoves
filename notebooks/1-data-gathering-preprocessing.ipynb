{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to data gathering and preprocessing. That is, with this notebook you'll be able to: download the data, unzip it (if necessary), and, finally, prepare the data for further vizualization and modeling.  \n",
    "\n",
    "In this study, we used open data from the following sources:\n",
    "1. London Datastore (London shape files);\n",
    "2. Office for National Statistics (London population);\n",
    "3. Transport for London (metro traffic);\n",
    "4. Wikimedia Commons (metro station locations);\n",
    "5. OpenStreetMaps (points of interest).\n",
    "\n",
    "The links to the data sets can be found in the __References section__. Besides that, we used results from Verma et al. (2020). In this work, authors proposed spatio-temporal clustering of London metro stations based on their traffic. We will use results of this clustering in the second notebook.\n",
    "\n",
    "To gather the data we used URL links to the websites of the data providers. Note, that the __data sets can be updated__ by corresponding agencies; therefore, some discrepancies are possible: new variables will become available, or some data set will have fewer attributes. To gather POIs data we used Python package OSMnx (Boeing, 2017).\n",
    "\n",
    "The notebook is split into three sections: Data Gathering, Data Preprocessing and References. Each of the sections consists of subsections covering different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikhail\\AppData\\Local\\Continuum\\miniconda3\\envs\\heatvuln\\lib\\site-packages\\pyrosm\\utils\\_compat.py:12: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). The tool will work but it runs a bit slower.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import requests, zipfile, io, os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from pyrosm import OSM\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__London shape files__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading date: 08-05-2020 19:59:41\n"
     ]
    }
   ],
   "source": [
    "url = 'https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "directory = \"../data/raw/geometry/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "\n",
    "z.extractall(path=directory)\n",
    "print(f'Downloading date: {datetime.today().strftime(\"%d-%m-%Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__London population__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading date: 08-05-2020 19:59:44\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.ons.gov.uk/file?uri=%2fpeoplepopulationandcommunity%2fpopulationandmigration%2fpopulationestimates%2fdatasets%2fcensusoutputareaestimatesinthelondonregionofengland%2fmid2017/sape20dt10amid2017coaunformattedsyoaestimateslondon.zip'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "directory = \"../data/raw/population/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "z.extractall(path=directory)\n",
    "print(f'Downloading date: {datetime.today().strftime(\"%d-%m-%Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OpenStreetMaps POIs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading date: 08-05-2020 19:59:50\n",
      "Wall time: 6.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "url = 'https://download.geofabrik.de/europe/great-britain/england/greater-london-latest.osm.pbf'\n",
    "r = requests.get(url)\n",
    "\n",
    "directory = \"../data/raw/pois/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "with open(directory + 'greater-london-latest.osm.pbf', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "print(f'Downloading date: {datetime.today().strftime(\"%d-%m-%Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize the OSM parser object\n",
    "osm = OSM('../data/raw/pois/greater-london-latest.osm.pbf')\n",
    "\n",
    "# By default pyrosm reads all elements having \"amenity\", \"shop\" or \"tourism\" tag\n",
    "# Here, let's read only \"amenity\" and \"shop\" by applying a custom filter that\n",
    "# overrides the default filtering mechanism\n",
    "\n",
    "# !!!: Not sure what are the other tags\n",
    "# custom_filter = {'amenity': True, \"shop\" : True, \"tourism\" : True}\n",
    "# pois = osm.get_pois(custom_filter=custom_filter)\n",
    "\n",
    "# Let's read everything\n",
    "pois = osm.get_pois()\n",
    "\n",
    "# Gather info about POI type (combines the tag info from \"amenity\" and \"shop\")\n",
    "pois[\"poi_type\"] = pois[\"amenity\"]\n",
    "# pois[\"poi_type\"] = pois[\"poi_type\"].fillna(pois[\"shop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116283, 120)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"../data/processed/pois/\"\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save complete data\n",
    "pois.to_csv(directory + \"pois.csv\", index=False)\n",
    "\n",
    "# Save only the columns of interest\n",
    "# pois = pois[[\"osmid\", \"geometry\", \"amenity\", \"name\", \"building\"]]\n",
    "# pois.to_file(directory + \"pois.json\", driver=\"GeoJSON\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Connect shape files and population__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load population data\n",
    "population = pd.read_excel(\"../data/raw/population/SAPE20DT10a-mid-2017-coa-unformatted-syoa-estimates-london.xlsx\", \n",
    "                           sheet_name=\"Mid-2017 Persons\", skiprows=4)  # the first 4 rows have irrelevant information, so skip them\n",
    "\n",
    "# Rename a column\n",
    "population.rename({\"All Ages\": \"total_population\"}, axis=1, inplace=True)\n",
    "\n",
    "# Select only the age groups of interest\n",
    "# The assumption is that only those people who are from the age of 18 to the age of 65 are working\n",
    "age_groups = [age for age in range(18, 65)]\n",
    "\n",
    "# Create adult population column\n",
    "population[\"adult_population\"] = population[age_groups].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge geometry and population data, both boroughs and wards\n",
    "geometry = gpd.read_file('../data/raw/geometry/statistical-gis-boundaries-london/ESRI/OA_2011_London_gen_MHW.shp')\n",
    "merged = pd.merge(geometry, population[[\"OA11CD\", \"total_population\", \"adult_population\"]], on=\"OA11CD\")                            \n",
    "boroughs = merged.dissolve(\"LAD11NM\", aggfunc=\"sum\", as_index=False)                            \n",
    "wards = merged.dissolve(\"WD11CD_BF\", aggfunc=\"sum\", as_index=False)\n",
    "\n",
    "# Define the directory to store the data\n",
    "directory = \"../data/processed/population/\"\n",
    "\n",
    "# Create it if needed\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "                \n",
    "# Save the data\n",
    "boroughs.to_file(directory + 'boroughs.json', driver='GeoJSON')\n",
    "wards.to_file(directory + 'wards.json', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__POIs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikhail\\AppData\\Local\\Continuum\\miniconda3\\envs\\heatvuln\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (9,20,21,25,26,28,29,30,31,32,33,34,35,36,37,38,39,41,42,46,47,48,52,54,55,56,57,58,59,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,86,87,89,90,91,92,93,94,95,96,97,98,100,101,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(116283, 120)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load POIs data\n",
    "pois = pd.read_csv(\"../data/processed/pois/pois.csv\")\n",
    "pois = gpd.GeoDataFrame(pois, geometry=gpd.points_from_xy(pois['lon'], pois['lat']))\n",
    "pois.crs = {'init' : 'epsg:4326'}\n",
    "pois.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes geometry of a POI is of _Multipolygon_ or _Polygon_ type. Let's convert it to _Point_ type for uniformity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change geometry\n",
    "pois['geometry'] = pois['geometry'].apply(lambda x:x.centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \"pois_categorization.csv\" we introduced a __subjective categorization__ of POIs into a set of categories. Let's assign these categories to the POIs that we've collected.\n",
    "\n",
    "Note that this categorization must be improved! Otherwise, we will lost something around 30000 POIs! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load categories and merge them with POIs data\n",
    "pois_categories = pd.read_csv(\"../data/external/pois_categories.csv\")\n",
    "pois = pd.merge(pois, pois_categories, left_on='amenity', right_on=\"pois\")\n",
    "pois.drop('amenity', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove amenities tagged 'misc'\n",
    "pois = pois[pois['pois_category'] != \"misc\"]\n",
    "\n",
    "# Drop duplicated amenities\n",
    "# pois = pois.drop_duplicates(subset=[\"geometry\", \"name\", \"pois\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikhail\\AppData\\Local\\Continuum\\miniconda3\\envs\\heatvuln\\lib\\site-packages\\geopandas\\tools\\sjoin.py:61: UserWarning: CRS of frames being joined does not match!({'init': 'epsg:27700', 'no_defs': True} != {'init': 'epsg:27700'})\n",
      "  \"(%s != %s)\" % (left_df.crs, right_df.crs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Merge POIs with geometry\n",
    "resolution = 'boroughs'\n",
    "polygons = gpd.read_file(f'../data/processed/population/{resolution}.json')\n",
    "pois_in_polygon = gpd.sjoin(pois.to_crs(epsg=27700), polygons, how=\"inner\", op=\"intersects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total counts of POIs types in each borough\n",
    "# Boroughs are tagged LAD11NM\n",
    "pois_counts = pois_in_polygon.groupby(['pois_category', 'LAD11NM']).agg(len)\n",
    "pois_counts = pois_counts.reset_index()\n",
    "pois_counts = pois_counts.pivot(index=\"pois_category\", columns =\"LAD11NM\", values= \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to store the data\n",
    "directory = \"../data/processed/pois/\"\n",
    "\n",
    "# Create it if needed\n",
    "if not os.path.exists(directory):\n",
    "    print(f'Succefully created new directory {directory}')\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the data\n",
    "pois_counts.to_csv(directory + f'pois_counts_{resolution}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## 3. References\n",
    "1. London Datastore (2019). Statistical GIS Boundary Files for London. Retrieved from https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london\n",
    "2. Office for National Statistics (2019). Census Output Area population estimates – London, England (supporting information). Retrieved from https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/censusoutputareaestimatesinthelondonregionofengland\n",
    "3. Transport for London (2020). Transport for London API. Retrieved from https://api-portal.tfl.gov.uk/docs\n",
    "4. Wikimedia Commons (2020). London Underground geographic maps/CSV. Retrieved from https://commons.wikimedia.org/wiki/London_Underground_geographic_maps/CSV\n",
    "5. OpenStreetMap contributors (2020). Amenities. Retrieved from https://www.openstreetmap.org.\n",
    "6. Verma, T., Sirenko, M., Kornecki, I., Cunningham S., Araujo, N. A. M. (2020) Temporal demand profiles of mobility reveal the spatial structure of a city. Manuscript in preparation.\n",
    "7. Boeing, G. (2017). OSMnx: New Methods for Acquiring, Constructing, Analyzing, and Visualizing Complex Street Networks. Computers, Environment and Urban Systems 65, 126-139. doi:10.1016/j.compenvurbsys.2017.05.004"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heatvuln",
   "language": "python",
   "name": "heatvuln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
